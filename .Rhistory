}
# 2) if still NA, try Indicator-only
if ("Indicator" %in% names(df)) {
df <- df %>%
group_by(Indicator) %>%
mutate(Value_num = ifelse(is.na(Value_num),
median(Value_num, na.rm = TRUE),
Value_num)) %>%
ungroup()
}
# 3) global fallback
if (any(is.na(df$Value_num))) {
gmed <- median(df$Value_num, na.rm = TRUE)
df$Value_num[is.na(df$Value_num)] <- gmed
}
df
}
df_clean <- lapply(df_clean, impute_group_median)
# 6.3 Winsorize (optional) to limit extreme outliers (only if Value_num exists)
winsorize <- function(x, p = c(0.01, 0.99)){
qs <- quantile(x, probs = p, na.rm = TRUE)
x <- pmax(x, qs[1]); x <- pmin(x, qs[2]); x
}
df_clean <- lapply(df_clean, function(df){
if ("Value_num" %in% names(df) && sum(!is.na(df$Value_num)) > 10) {
df$Value_winz <- winsorize(df$Value_num)
}
df
})
# 6.4 Cast categorical columns to factor & build scaled numeric
prep_factors_scale <- function(df){
for (v in c("Sex","Age","Region","Subgroup","Indicator","Period")){
if (v %in% names(df)) df[[v]] <- as.factor(df[[v]])
}
if ("Value_winz" %in% names(df)) {
df$Value_scaled <- as.numeric(scale(df$Value_winz))
} else if ("Value_num" %in% names(df)) {
df$Value_scaled <- as.numeric(scale(df$Value_num))
}
df
}
df_clean <- lapply(df_clean, prep_factors_scale)
# Save interim cleaned CSVs
purrr::iwalk(df_clean, ~write.csv(.x, file.path(out_dir, paste0("clean_", .y, ".csv")), row.names = FALSE))
# Helper: collect numeric predictors (excluding target derivations)
num_preds <- function(df){
nums <- names(df)[sapply(df, is.numeric)]
setdiff(nums, c("Value_num","Value_winz","Value_scaled"))
}
# Spearman
spearman_report <- function(df, name){
out <- tibble()
if ("Value_scaled" %in% names(df)) {
for (nm in num_preds(df)) {
x <- df[[nm]]
if (length(unique(na.omit(x))) > 5) {
ct <- suppressWarnings(cor.test(df$Value_scaled, x, method = "spearman"))
out <- bind_rows(out, tibble(Predictor = nm, Rho = unname(ct$estimate), P = ct$p.value))
}
}
}
out %>% mutate(Dataset = name)
}
spearman_all <- purrr::imap_dfr(df_clean, spearman_report)
knitr::kable(head(arrange(spearman_all, P), 15), caption = "Top Numeric Predictors by Spearman (smallest p-values)")
knitr::opts_chunk$set(echo = TRUE)
# Adjust paths if your CSVs live elsewhere
paths <- list(
Anthropometry     = "anthropometry_national_zaf.csv",
Literacy          = "literacy_national_zaf.csv",
MaternalMortality = "maternal-mortality_national_zaf.csv",
ARI_Symptoms      = "symptoms-of-acute-respiratory-infection-ari_national_zaf.csv"
)
read_base <- function(p) read.csv(p, stringsAsFactors = FALSE, check.names = FALSE)
df_list_raw <- lapply(paths, read_base)
names(df_list_raw) <- names(paths)
# Output directory
out_dir <- "outputs_m2"
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
# Standardize names + parse Value -> Value_num (handles "12%", "1,234", etc.)
clean_df <- function(df){
# unify column names
names(df) <- gsub("\\s+", "_", names(df))
names(df) <- gsub("[^A-Za-z0-9_]", "", names(df))
# numeric extraction for Value
if ("Value" %in% names(df)) {
df$Value_num <- readr::parse_number(as.character(df$Value))
}
df
}
df_list <- lapply(df_list_raw, clean_df)
# Quick sanity: which datasets had non-numeric Value originally?
for (nm in names(df_list)) {
df <- df_list[[nm]]
if ("Value" %in% names(df)) {
bad <- suppressWarnings(sum(is.na(as.numeric(df$Value)) & !is.na(df$Value)))
cat(nm, "- non-numeric Value entries initially:", bad, "\n")
}
}
dims <- tibble(
Dataset = names(df_list),
Rows    = sapply(df_list, nrow),
Columns = sapply(df_list, ncol)
)
# Show first 8 column names for each dataset
col_preview <- purrr::imap_dfr(df_list, ~tibble(
Dataset = .y,
Columns = paste(head(names(.x), 8), collapse = ", ")
))
knitr::kable(dims, caption = "Dataset Dimensions (Before Selection)")
knitr::kable(col_preview, caption = "Column Preview (First 8 per Dataset)")
keep_cols <- c("Indicator","Value","Value_num","Sex","Age","Region","Period","Subgroup")
prune_by_cols <- function(df) {
cols <- intersect(keep_cols, names(df))
df[, cols, drop = FALSE]
}
df_sel <- lapply(df_list, prune_by_cols)
# Missing rate per column
col_missing_rate <- function(df) {
tibble(
Column     = names(df),
Missing    = sapply(df, function(x) sum(is.na(x))),
PctMissing = round(100 * sapply(df, function(x) sum(is.na(x))) / max(1, nrow(df)), 2)
) %>% arrange(desc(PctMissing))
}
missing_reports <- purrr::imap(df_sel, ~col_missing_rate(.x) %>% mutate(Dataset = .y))
missing_overview <- dplyr::bind_rows(missing_reports)
# Drop columns with > 40% missing unless they are on a small list of essentials
essentials <- c("Indicator","Value_num")  # keep if available
drop_by_missing <- function(df, threshold = 40){
rates <- 100 * sapply(df, function(x) sum(is.na(x))) / max(1, nrow(df))
keep <- names(df)[rates <= threshold | names(df) %in% essentials]
df[, keep, drop = FALSE]
}
df_sel <- lapply(df_sel, drop_by_missing, threshold = 40)
knitr::kable(head(missing_overview, 30), caption = "Missingness Overview (Top 30 Rows)")
# 6.1 Remove exact duplicates
df_clean <- lapply(df_sel, function(df) df[!duplicated(df), , drop = FALSE])
# 6.2 Impute Value_num
impute_group_median <- function(df) {
if (!"Value_num" %in% names(df)) return(df)
# 1) try Indicator x Sex
if (all(c("Indicator","Sex") %in% names(df))) {
df <- df %>%
group_by(Indicator, Sex) %>%
mutate(Value_num = ifelse(is.na(Value_num),
median(Value_num, na.rm = TRUE),
Value_num)) %>%
ungroup()
}
# 2) if still NA, try Indicator-only
if ("Indicator" %in% names(df)) {
df <- df %>%
group_by(Indicator) %>%
mutate(Value_num = ifelse(is.na(Value_num),
median(Value_num, na.rm = TRUE),
Value_num)) %>%
ungroup()
}
# 3) global fallback
if (any(is.na(df$Value_num))) {
gmed <- median(df$Value_num, na.rm = TRUE)
df$Value_num[is.na(df$Value_num)] <- gmed
}
df
}
df_clean <- lapply(df_clean, impute_group_median)
# 6.3 Winsorize (optional) to limit extreme outliers (only if Value_num exists)
winsorize <- function(x, p = c(0.01, 0.99)){
qs <- quantile(x, probs = p, na.rm = TRUE)
x <- pmax(x, qs[1]); x <- pmin(x, qs[2]); x
}
df_clean <- lapply(df_clean, function(df){
if ("Value_num" %in% names(df) && sum(!is.na(df$Value_num)) > 10) {
df$Value_winz <- winsorize(df$Value_num)
}
df
})
# 6.4 Cast categorical columns to factor & build scaled numeric
prep_factors_scale <- function(df){
for (v in c("Sex","Age","Region","Subgroup","Indicator","Period")){
if (v %in% names(df)) df[[v]] <- as.factor(df[[v]])
}
if ("Value_winz" %in% names(df)) {
df$Value_scaled <- as.numeric(scale(df$Value_winz))
} else if ("Value_num" %in% names(df)) {
df$Value_scaled <- as.numeric(scale(df$Value_num))
}
df
}
df_clean <- lapply(df_clean, prep_factors_scale)
# Save interim cleaned CSVs
purrr::iwalk(df_clean, ~write.csv(.x, file.path(out_dir, paste0("clean_", .y, ".csv")), row.names = FALSE))
# Helper: collect numeric predictors (excluding target derivations)
num_preds <- function(df){
nums <- names(df)[sapply(df, is.numeric)]
setdiff(nums, c("Value_num","Value_winz","Value_scaled"))
}
# Spearman
spearman_report <- function(df, name){
out <- tibble()
if ("Value_scaled" %in% names(df)) {
for (nm in num_preds(df)) {
x <- df[[nm]]
if (length(unique(na.omit(x))) > 5) {
ct <- suppressWarnings(cor.test(df$Value_scaled, x, method = "spearman"))
out <- bind_rows(out, tibble(Predictor = nm, Rho = unname(ct$estimate), P = ct$p.value))
}
}
}
out %>% mutate(Dataset = name)
}
spearman_all <- purrr::imap_dfr(df_clean, spearman_report)
knitr::kable(head(arrange(spearman_all, P), 15), caption = "Top Numeric Predictors by Spearman (smallest p-values)")
knitr::opts_chunk$set(echo = TRUE)
# Adjust paths if your CSVs live elsewhere
paths <- list(
Anthropometry     = "anthropometry_national_zaf.csv",
Literacy          = "literacy_national_zaf.csv",
MaternalMortality = "maternal-mortality_national_zaf.csv",
ARI_Symptoms      = "symptoms-of-acute-respiratory-infection-ari_national_zaf.csv"
)
read_base <- function(p) read.csv(p, stringsAsFactors = FALSE, check.names = FALSE)
df_list_raw <- lapply(paths, read_base)
names(df_list_raw) <- names(paths)
# Output directory
out_dir <- "outputs_m2"
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
# Standardize names + parse Value -> Value_num (handles "12%", "1,234", etc.)
clean_df <- function(df){
# unify column names
names(df) <- gsub("\\s+", "_", names(df))
names(df) <- gsub("[^A-Za-z0-9_]", "", names(df))
# numeric extraction for Value
if ("Value" %in% names(df)) {
df$Value_num <- readr::parse_number(as.character(df$Value))
}
df
}
df_list <- lapply(df_list_raw, clean_df)
# Quick sanity: which datasets had non-numeric Value originally?
for (nm in names(df_list)) {
df <- df_list[[nm]]
if ("Value" %in% names(df)) {
bad <- suppressWarnings(sum(is.na(as.numeric(df$Value)) & !is.na(df$Value)))
cat(nm, "- non-numeric Value entries initially:", bad, "\n")
}
}
dims <- tibble(
Dataset = names(df_list),
Rows    = sapply(df_list, nrow),
Columns = sapply(df_list, ncol)
)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)  # dplyr, tidyr, ggplot2, readr, purrr
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
suppressWarnings(suppressMessages({
if (!requireNamespace("tidyverse", quietly = TRUE)) install.packages("tidyverse")
library(tidyverse)  # dplyr, tidyr, ggplot2, readr, purrr
}))
knitr::opts_chunk$set(echo = TRUE)
# Adjust paths if your CSVs live elsewhere
paths <- list(
Anthropometry     = "anthropometry_national_zaf.csv",
Literacy          = "literacy_national_zaf.csv",
MaternalMortality = "maternal-mortality_national_zaf.csv",
ARI_Symptoms      = "symptoms-of-acute-respiratory-infection-ari_national_zaf.csv"
)
read_base <- function(p) read.csv(p, stringsAsFactors = FALSE, check.names = FALSE)
df_list_raw <- lapply(paths, read_base)
names(df_list_raw) <- names(paths)
# Output directory
out_dir <- "outputs_m2"
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
# Standardize names + parse Value -> Value_num (handles "12%", "1,234", etc.)
clean_df <- function(df){
# unify column names
names(df) <- gsub("\\s+", "_", names(df))
names(df) <- gsub("[^A-Za-z0-9_]", "", names(df))
# numeric extraction for Value
if ("Value" %in% names(df)) {
df$Value_num <- readr::parse_number(as.character(df$Value))
}
df
}
df_list <- lapply(df_list_raw, clean_df)
# Quick sanity: which datasets had non-numeric Value originally?
for (nm in names(df_list)) {
df <- df_list[[nm]]
if ("Value" %in% names(df)) {
bad <- suppressWarnings(sum(is.na(as.numeric(df$Value)) & !is.na(df$Value)))
cat(nm, "- non-numeric Value entries initially:", bad, "\n")
}
}
dims <- tibble(
Dataset = names(df_list),
Rows    = sapply(df_list, nrow),
Columns = sapply(df_list, ncol)
)
# Show first 8 column names for each dataset
col_preview <- purrr::imap_dfr(df_list, ~tibble(
Dataset = .y,
Columns = paste(head(names(.x), 8), collapse = ", ")
))
knitr::kable(dims, caption = "Dataset Dimensions (Before Selection)")
knitr::kable(col_preview, caption = "Column Preview (First 8 per Dataset)")
keep_cols <- c("Indicator","Value","Value_num","Sex","Age","Region","Period","Subgroup")
prune_by_cols <- function(df) {
cols <- intersect(keep_cols, names(df))
df[, cols, drop = FALSE]
}
df_sel <- lapply(df_list, prune_by_cols)
# Missing rate per column
col_missing_rate <- function(df) {
tibble(
Column     = names(df),
Missing    = sapply(df, function(x) sum(is.na(x))),
PctMissing = round(100 * sapply(df, function(x) sum(is.na(x))) / max(1, nrow(df)), 2)
) %>% arrange(desc(PctMissing))
}
missing_reports <- purrr::imap(df_sel, ~col_missing_rate(.x) %>% mutate(Dataset = .y))
missing_overview <- dplyr::bind_rows(missing_reports)
# Drop columns with > 40% missing unless essential
essentials <- c("Indicator","Value_num")
drop_by_missing <- function(df, threshold = 40){
rates <- 100 * sapply(df, function(x) sum(is.na(x))) / max(1, nrow(df))
keep <- names(df)[rates <= threshold | names(df) %in% essentials]
df[, keep, drop = FALSE]
}
df_sel <- lapply(df_sel, drop_by_missing, threshold = 40)
knitr::kable(head(missing_overview, 30), caption = "Missingness Overview (Top 30 Rows)")
# 6.1 Remove exact duplicates
df_clean <- lapply(df_sel, function(df) df[!duplicated(df), , drop = FALSE])
# 6.2 Impute Value_num
impute_group_median <- function(df) {
if (!"Value_num" %in% names(df)) return(df)
# by Indicator x Sex
if (all(c("Indicator","Sex") %in% names(df))) {
df <- df %>%
group_by(Indicator, Sex) %>%
mutate(Value_num = ifelse(is.na(Value_num),
median(Value_num, na.rm = TRUE),
Value_num)) %>%
ungroup()
}
# by Indicator
if ("Indicator" %in% names(df)) {
df <- df %>%
group_by(Indicator) %>%
mutate(Value_num = ifelse(is.na(Value_num),
median(Value_num, na.rm = TRUE),
Value_num)) %>%
ungroup()
}
# global fallback
if (any(is.na(df$Value_num))) {
gmed <- median(df$Value_num, na.rm = TRUE)
df$Value_num[is.na(df$Value_num)] <- gmed
}
df
}
df_clean <- lapply(df_clean, impute_group_median)
# 6.3 Winsorize (optional)
winsorize <- function(x, p = c(0.01, 0.99)){
qs <- quantile(x, probs = p, na.rm = TRUE)
x <- pmax(x, qs[1]); x <- pmin(x, qs[2]); x
}
df_clean <- lapply(df_clean, function(df){
if ("Value_num" %in% names(df) && sum(!is.na(df$Value_num)) > 10) {
df$Value_winz <- winsorize(df$Value_num)
}
df
})
# 6.4 Cast factors & scale
prep_factors_scale <- function(df){
for (v in c("Sex","Age","Region","Subgroup","Indicator","Period")){
if (v %in% names(df)) df[[v]] <- as.factor(df[[v]])
}
if ("Value_winz" %in% names(df)) {
df$Value_scaled <- as.numeric(scale(df$Value_winz))
} else if ("Value_num" %in% names(df)) {
df$Value_scaled <- as.numeric(scale(df$Value_num))
}
df
}
df_clean <- lapply(df_clean, prep_factors_scale)
# Save interim cleaned CSVs
purrr::iwalk(df_clean, ~write.csv(.x, file.path(out_dir, paste0("clean_", .y, ".csv")), row.names = FALSE))
# Helper: numeric predictors (excluding target variants)
num_preds <- function(df){
nums <- names(df)[sapply(df, is.numeric)]
setdiff(nums, c("Value_num","Value_winz","Value_scaled"))
}
# OPTIONAL numeric 'Period_num' to enable at least one numeric predictor
df_clean <- lapply(df_clean, function(df){
if ("Period" %in% names(df) && !("Period_num" %in% names(df))) {
df$Period_num <- as.numeric(df$Period)  # encoded levels; interpret cautiously
}
df
})
# Spearman (robust to empty results)
spearman_report <- function(df, name){
out <- tibble()
if ("Value_scaled" %in% names(df)) {
preds <- num_preds(df)
if (length(preds) > 0) {
for (nm in preds) {
x <- df[[nm]]
if (length(unique(na.omit(x))) > 5) {
ct <- suppressWarnings(cor.test(df$Value_scaled, x, method = "spearman"))
out <- bind_rows(out, tibble(Predictor = nm, Rho = unname(ct$estimate), P = ct$p.value))
}
}
}
}
if (nrow(out) == 0) out <- tibble(Predictor = NA_character_, Rho = NA_real_, P = NA_real_)
out %>% mutate(Dataset = name)
}
spearman_all <- purrr::imap_dfr(df_clean, spearman_report)
if ("P" %in% names(spearman_all) && any(!is.na(spearman_all$P))) {
knitr::kable(dplyr::arrange(spearman_all, P) %>% head(15),
caption = "Top Numeric Predictors by Spearman (smallest p-values)")
} else {
knitr::kable(spearman_all,
caption = "Spearman results (none available — no eligible numeric predictors)")
}
# Kruskal–Wallis (categorical vs Value_scaled)
kw_report <- function(df, name){
out <- tibble()
if ("Value_scaled" %in% names(df)) {
cats <- names(df)[sapply(df, is.factor)]
for (nm in cats) {
if (length(unique(na.omit(df[[nm]]))) >= 2) {
kt <- suppressWarnings(kruskal.test(Value_scaled ~ df[[nm]], data = df))
out <- bind_rows(out, tibble(Variable = nm, KW_ChiSq = unname(kt$statistic), P = kt$p.value))
}
}
}
if (nrow(out) == 0) out <- tibble(Variable = NA_character_, KW_ChiSq = NA_real_, P = NA_real_)
out %>% mutate(Dataset = name)
}
kw_all <- purrr::imap_dfr(df_clean, kw_report)
if ("P" %in% names(kw_all) && any(!is.na(kw_all$P))) {
knitr::kable(dplyr::arrange(kw_all, P) %>% head(15),
caption = "Top Categorical Predictors by Kruskal–Wallis (smallest p-values)")
} else {
knitr::kable(kw_all, caption = "Kruskal–Wallis results (none available)")
}
# One-hot encode via model.matrix; Value_scaled is the numeric response proxy
one_hot_mats <- lapply(df_clean, function(df){
if (!"Value_scaled" %in% names(df)) return(NULL)
mm <- model.matrix(Value_scaled ~ . - Value - Value_num - Value_winz, data = df)
list(
X = as.matrix(mm),
y = as.numeric(df$Value_scaled)
)
})
dir.create(out_dir, showWarnings = FALSE)
set.seed(42)
split_and_save <- function(name, mat_list){
if (is.null(mat_list)) return(invisible(NULL))
n <- length(mat_list$y)
idx <- sample(seq_len(n), size = max(1, floor(0.7*n)))
train <- list(X = mat_list$X[idx, , drop = FALSE], y = mat_list$y[idx])
test  <- list(X = mat_list$X[-idx, , drop = FALSE], y = mat_list$y[-idx])
saveRDS(train, file.path(out_dir, paste0("train_", name, ".rds")))
saveRDS(test,  file.path(out_dir, paste0("test_",  name, ".rds")))
invisible(TRUE)
}
purrr::iwalk(one_hot_mats, split_and_save)
knitr::opts_chunk$set(echo = TRUE)
# One-hot encode via model.matrix; Value_scaled is the numeric response proxy
one_hot_mats <- lapply(df_clean, function(df){
if (!"Value_scaled" %in% names(df)) return(NULL)
mm <- model.matrix(Value_scaled ~ . - Value - Value_num - Value_winz, data = df)
list(
X = as.matrix(mm),
y = as.numeric(df$Value_scaled)
)
})
dir.create(out_dir, showWarnings = FALSE)
set.seed(42)
# NOTE: iwalk passes (value, name), so function must be (mat_list, name)
split_and_save <- function(mat_list, name){
if (is.null(mat_list)) return(invisible(NULL))
n <- length(mat_list$y)
if (n < 2) return(invisible(NULL))  # nothing to split
idx <- sample(seq_len(n), size = max(1, floor(0.7 * n)))
train <- list(X = mat_list$X[idx, , drop = FALSE], y = mat_list$y[idx])
test  <- list(X = mat_list$X[-idx, , drop = FALSE], y = mat_list$y[-idx])
saveRDS(train, file.path(out_dir, paste0("train_", name, ".rds")))
saveRDS(test,  file.path(out_dir, paste0("test_",  name, ".rds")))
invisible(TRUE)
}
purrr::iwalk(one_hot_mats, split_and_save)
# Missingness after cleaning
clean_missing_reports <- purrr::imap(df_clean, ~tibble(
Dataset    = .y,
MissingTot = sum(sapply(.x, function(c) sum(is.na(c)))),
Rows       = nrow(.x)
))
knitr::kable(clean_missing_reports, caption = "Missingness After Cleaning (Total NA counts)")
# Outliers (IQR) count on Value_num (pre-winsor) if present
iqr_flags <- function(x){
q1 <- quantile(x, 0.25, na.rm=TRUE); q3 <- quantile(x, 0.75, na.rm=TRUE); i <- q3-q1
(x < (q1 - 1.5*i)) | (x > (q3 + 1.5*i))
}
outlier_report <- purrr::imap_dfr(df_clean, function(df, nm){
if (!"Value_num" %in% names(df)) return(tibble(Dataset = nm, Outliers_Value_num = NA_integer_))
tibble(Dataset = nm, Outliers_Value_num = sum(iqr_flags(df$Value_num), na.rm = TRUE))
})
knitr::kable(outlier_report, caption = "Outliers (IQR) Count on Value_num (Pre-Winsor)")
